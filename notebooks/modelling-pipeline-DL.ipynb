{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad604686",
   "metadata": {},
   "source": [
    "## Modeling Pipeline - Deep Learning\n",
    "\n",
    "This notebook focuses on the development of project ML/DL models - focus on modelling pipeline setup & **baseline** models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe477e45",
   "metadata": {},
   "source": [
    "### Research Questions:\n",
    "\n",
    "1. Build baseline ML and DL models\n",
    "2. Build optimized ML and DL models\n",
    "3. Are optimized models better -> how much?\n",
    "4. Is baseline DL model better than optimized ML model?\n",
    "5. Knowledge distillation:\n",
    "    - is distilled ML model better than optmized ML model?\n",
    "    - is distilled ML model better than baseline DL model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a42fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.dont_write_bytecode = True\n",
    "root_dir = os.path.abspath(os.pardir)\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c80be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from configs.constants import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "684a6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf568bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448c8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/preprocessing/ML/'\n",
    "meta_df_file = '../data/results/complete_metadata_mapping_2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b53142",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83397fa",
   "metadata": {},
   "source": [
    "train test split indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abde9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(meta_df_file)\n",
    "meta_df['dx_codes'] = meta_df['dx_codes'].map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f2806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = meta_df.drop('dx_codes', axis=1)\n",
    "y = meta_df['dx_codes']\n",
    "\n",
    "X_work, X_test, y_work, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=TTS_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f384d7",
   "metadata": {},
   "source": [
    "train/validation split\n",
    "\n",
    "- in order to avoid optimistic metrics we evaluate on test data once and calibrate on eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd9fb11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_work, y_work, test_size=0.1, random_state=TTS_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc03524",
   "metadata": {},
   "source": [
    "**model preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f964376",
   "metadata": {},
   "source": [
    "label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53dd42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train_transformed = mlb.fit_transform(y_train)\n",
    "y_val_transformed = mlb.transform(y_val)\n",
    "y_test_transformed = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1dd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9edf7d1c",
   "metadata": {},
   "source": [
    "___\n",
    "#### **DL (Deep Learning)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc43cc",
   "metadata": {},
   "source": [
    "pytorch installation test + GPU support check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6093a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a542de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5955, 0.0385, 0.0434],\n",
      "        [0.2217, 0.4618, 0.0509],\n",
      "        [0.4574, 0.9149, 0.1969],\n",
      "        [0.3824, 0.3900, 0.4294],\n",
      "        [0.8161, 0.1438, 0.4660]])\n",
      "True\n",
      "cuda device count: 1\n",
      "cuda device name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "if cuda:\n",
    "    print(\"cuda device count:\", torch.cuda.device_count())\n",
    "    print(\"cuda device name:\", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd16da",
   "metadata": {},
   "source": [
    "DL preprocessing\n",
    "- we will pass raw ECG signals mapped per row (instead of calculating features as in ML pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff612da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    \"\"\"\n",
    "    df: pandas DataFrame with a column containing WFDB record base paths\n",
    "    Y:  numpy array float32 of shape [N, C] (multi-hot targets)\n",
    "    Returns:\n",
    "      x: torch.FloatTensor [leads, T]\n",
    "      y: torch.FloatTensor [C]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, y, record_col='record_path', dtype=np.float32):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.y = np.asarray(y, dtype=np.float32)\n",
    "        self.record_col = record_col\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if len(self.df) != self.y.shape[0]:\n",
    "            raise ValueError(f\"df has {len(self.df)} rows but Y has {self.Y.shape[0]} rows\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.df.loc[idx, self.record_col]\n",
    "\n",
    "        try:\n",
    "            signals, _fields = wfdb.rdsamp(rec)\n",
    "            signals = np.asarray(signals, dtype=self.dtype)\n",
    "            \n",
    "            x = torch.from_numpy(signals.T)\n",
    "            y = torch.from_numpy(self.y[idx])\n",
    "            return x, y\n",
    "        except Exception as e:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9e3a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_skip_none(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    return default_collate(batch)\n",
    "\n",
    "\n",
    "def make_loader(dataset, batch_size, shuffle, num_workers=4):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        collate_fn=collate_skip_none\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709f4d0",
   "metadata": {},
   "source": [
    "load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74f57e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_first_n(dataset, n=10, expected_leads=12):\n",
    "    ok = {}\n",
    "    bad = []\n",
    "\n",
    "    for i in range(min(n, len(dataset))):\n",
    "        item = dataset[i]\n",
    "        if item is None:\n",
    "            bad.append(i)\n",
    "        \n",
    "        if len(item) == 2:\n",
    "            x, y = item\n",
    "            rec = dataset.df.iloc[i][dataset.record_col]\n",
    "        \n",
    "        ok[rec] = {\n",
    "            'X' : x,\n",
    "            'y' : y\n",
    "        }\n",
    "\n",
    "    return ok, bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53cfb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds10 = ECGDataset(X_train.iloc[:10], y_train_transformed[:10], record_col='record_path')\n",
    "ok, bad = test_first_n(ds10, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac7fae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72a19189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(ok))\n",
    "print(len(bad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d3b02c",
   "metadata": {},
   "source": [
    "baseline model:\n",
    "1. simple CNN - ECG only\n",
    "2. simple CNN - ECG + meta attributes (age, sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b22b3b",
   "metadata": {},
   "source": [
    "1. ECG only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c856372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallECGCNN(nn.Module):\n",
    "    def __init__(self, n_labels: int):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv1d(12, 32, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.head = nn.Linear(128, n_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        return self.head(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "428e7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_seen = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        x, y = batch\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n_seen += bs\n",
    "\n",
    "    return total_loss / max(n_seen, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loss(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n_seen = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        x, y = batch\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n_seen += bs\n",
    "\n",
    "    return total_loss / max(n_seen, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb38e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68512c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ds = ECGDataset(X_train, y_train_transformed, record_col='record_path')\n",
    "X_val_ds = ECGDataset(X_val, y_val_transformed, record_col='record_path')\n",
    "\n",
    "train_loader = make_loader(X_train_ds, batch_size=64, shuffle=True, num_workers=num_workers)\n",
    "val_loader   = make_loader(X_val_ds, batch_size=64, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "channels = y_train_transformed.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe2997",
   "metadata": {},
   "source": [
    "load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c010c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "while batch is None:\n",
    "    batch = next(iter(train_loader))\n",
    "x0, y0 = batch\n",
    "\n",
    "# result [B, 12, T] and [B, C]\n",
    "print(\"x batch:\", x0.shape, \"y batch:\", y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb63f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "MODEL_DIR = '../models/'\n",
    "model_name = 'baseline_cnn_ecg_modality.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91d3a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallECGCNN(n_labels=channels).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a709c16",
   "metadata": {},
   "source": [
    "baseline model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1fe3103",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m best_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     tr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     va \u001b[38;5;241m=\u001b[39m eval_loss(model, val_loader, criterion, device)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[53], line 6\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m      3\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m n_seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:206\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    204\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(batch)\n\u001b[0;32m    205\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:206\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(batch)\n\u001b[0;32m    205\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "best_val = float('inf')\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    tr = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    va = eval_loss(model, val_loader, criterion, device)\n",
    "    print(f\"epoch={epoch} train_loss={tr:.4f} val_loss={va:.4f}\")\n",
    "\n",
    "    if va < best_val:\n",
    "        best_val = va\n",
    "        model_path = os.path.abspath(os.path.join(MODEL_DIR, model_name))\n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da1fa6",
   "metadata": {},
   "source": [
    "Optimized architectures:\n",
    "- Multimodal: ECG + meta (sex, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fa0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e05dbad7",
   "metadata": {},
   "source": [
    "#### Evaluation system - TODO\n",
    "\n",
    "1. Multi-label classification eval\n",
    "2. Problem decomposition eval:\n",
    "    - single-classification part (rhytm prediction)\n",
    "    - multi-classification part (conditions prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47b991fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    hamming_loss,\n",
    "    confusion_matrix,\n",
    "    multilabel_confusion_matrix,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06a38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17c5a1f5",
   "metadata": {},
   "source": [
    "___\n",
    "#### xAI: Model Explainability\n",
    "ideas:\n",
    "- integrated gradients\n",
    "- knowledge distillation: DL -> ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a4178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

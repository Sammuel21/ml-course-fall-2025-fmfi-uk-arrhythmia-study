{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94251629",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The purpose of this notebook is to prepare and understand the working dataset for ML purposes. Important part is to split the data into modeling data  \n",
    "and testing data - this is important as we must completely isolate the testing data in order to avoid any data and statistical leaks.\n",
    "\n",
    "#### Goals:\n",
    "- understand data structure\n",
    "- load and compile data into one dataset\n",
    "- map metadata to corresponding ECG signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab8bb71",
   "metadata": {},
   "source": [
    "### Data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f62ec2",
   "metadata": {},
   "source": [
    "Shape:\n",
    "- 45 152 patients -> signals 10-second 12-lead ECG at 500 Hz -> 5000 samples per lead\n",
    "- WFDB format (WaveForm Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6c465",
   "metadata": {},
   "source": [
    "ECG = pair of files:\n",
    "- JS0000X.hea - ASCII WFDB header + metadata -> description of the data\n",
    "- JS0000X.mat - binary data matrix (val matrix in raw units) - 10-second 12-lead ECG samples in binary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e238e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ecg-arrhythmia/\n",
    "    WFDBRecords/\n",
    "        01/\n",
    "            010/\n",
    "                JS00001.hea\n",
    "                JS00001.mat\n",
    "                JS00002.hea\n",
    "                JS00002.mat\n",
    "                ...\n",
    "        02/\n",
    "        ...\n",
    "        46/\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23689e1a",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8b11d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.dont_write_bytecode = True\n",
    "root_dir = os.path.abspath(os.pardir)\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c15c46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from configs.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe0e11a",
   "metadata": {},
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53dc2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_folder_path = os.path.abspath(os.path.join(root_dir, DATA_DIR_FOLDER))\n",
    "data_dir_path = os.path.abspath(os.path.join(data_dir_folder_path, DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97331f2",
   "metadata": {},
   "source": [
    "#### Data Load Pipeline\n",
    "\n",
    "1. Load pipeline\n",
    "2. Feature Extraction pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127dbf80",
   "metadata": {},
   "source": [
    "common load - metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6675296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_header_paths(root_dir, dirname=\"WFDBRecords\"):\n",
    "    wfdb_root = os.path.join(root_dir, dirname)\n",
    "\n",
    "    for d1 in sorted(os.listdir(wfdb_root)):\n",
    "        p1 = os.path.join(wfdb_root, d1)\n",
    "        if not os.path.isdir(p1):\n",
    "            continue\n",
    "\n",
    "        for d2 in sorted(os.listdir(p1)):\n",
    "            p2 = os.path.join(p1, d2)\n",
    "            if not os.path.isdir(p2):\n",
    "                continue\n",
    "\n",
    "            for fname in sorted(os.listdir(p2)):\n",
    "                if fname.endswith(\".hea\"):\n",
    "                    yield os.path.join(p2, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82a55354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_header(header_path):\n",
    "    header_path = os.fspath(header_path)\n",
    "    with open (header_path, encoding='utf-8') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    if not lines:\n",
    "        raise ValueError(f'Empty header file: {header_path}')\n",
    "    \n",
    "    first = lines[0].strip().split()\n",
    "\n",
    "    # bugfix -> ked chyba prvy metadata riadok\n",
    "    offset = 1\n",
    "    try:\n",
    "        record_name = first[0]\n",
    "        n_signals = first[1]\n",
    "        freq = int(first[2])\n",
    "        n_samples = int(first[3])\n",
    "    except:\n",
    "        record_name = None\n",
    "        n_signals = None\n",
    "        freq = None\n",
    "        n_samples = None\n",
    "        offset = 0\n",
    "\n",
    "    lines = lines[offset:]\n",
    "\n",
    "    age = None\n",
    "    sex = None\n",
    "    y_dx_codes = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('#Age:'):\n",
    "            _, v = line.split(':', 1)\n",
    "            v = v.strip()\n",
    "            if v and v.lower() not in ['unknown', 'nan']:\n",
    "                try:\n",
    "                    age = int(v)\n",
    "                except ValueError:\n",
    "                    age = None\n",
    "        elif line.startswith('#Sex:'):\n",
    "            _, v = line.split(\":\", 1)\n",
    "            sex = v.strip() or None\n",
    "\n",
    "        elif line.startswith(\"#Dx:\"):\n",
    "            _, v = line.split(\":\", 1)\n",
    "            codes = [c.strip() for c in v.split(\",\") if c.strip()]\n",
    "            dx_codes = []\n",
    "            for c in codes:\n",
    "                try:\n",
    "                    dx_codes.append(int(c))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "    base, _ = os.path.splitext(header_path)\n",
    "    record_path = base\n",
    "\n",
    "    return {\n",
    "        \"record\": record_name,\n",
    "        \"hea_path\": header_path,\n",
    "        \"record_path\": record_path,\n",
    "        \"n_sig\": n_signals,\n",
    "        \"fs\": freq,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"age\": age,\n",
    "        \"sex\": sex,\n",
    "        \"dx_codes\": dx_codes,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976cd727",
   "metadata": {},
   "source": [
    "label loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0ee4d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(dirpath, filepath, as_index=False, index_column='Snomed_CT'):\n",
    "    filepath = os.path.join(dirpath, filepath)\n",
    "    data = pd.read_csv(filepath)\n",
    "    if as_index:\n",
    "        data = data.set_index(index_column)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "545a268c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acronym Name</th>\n",
       "      <th>Full Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snomed_CT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270492004</th>\n",
       "      <td>1AVB</td>\n",
       "      <td>1 degree atrioventricular block</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195042002</th>\n",
       "      <td>2AVB</td>\n",
       "      <td>2 degree atrioventricular block</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54016002</th>\n",
       "      <td>2AVB1</td>\n",
       "      <td>2 degree atrioventricular block(Type one)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28189009</th>\n",
       "      <td>2AVB2</td>\n",
       "      <td>2 degree atrioventricular block(Type two)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27885002</th>\n",
       "      <td>3AVB</td>\n",
       "      <td>3 degree atrioventricular block</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426761007</th>\n",
       "      <td>SVT</td>\n",
       "      <td>Supraventricular Tachycardia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713422000</th>\n",
       "      <td>AT</td>\n",
       "      <td>Atrial Tachycardia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233896004</th>\n",
       "      <td>AVNRT</td>\n",
       "      <td>Atrioventricular  Node Reentrant Tachycardia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233897008</th>\n",
       "      <td>AVRT</td>\n",
       "      <td>Atrioventricular Reentrant Tachycardia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195101003</th>\n",
       "      <td>SAAWR</td>\n",
       "      <td>Sinus Atrium to Atrial Wandering Rhythm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Acronym Name                                     Full Name\n",
       "Snomed_CT                                                           \n",
       "270492004         1AVB               1 degree atrioventricular block\n",
       "195042002         2AVB               2 degree atrioventricular block\n",
       "54016002         2AVB1     2 degree atrioventricular block(Type one)\n",
       "28189009         2AVB2     2 degree atrioventricular block(Type two)\n",
       "27885002          3AVB               3 degree atrioventricular block\n",
       "...                ...                                           ...\n",
       "426761007          SVT                  Supraventricular Tachycardia\n",
       "713422000           AT                            Atrial Tachycardia\n",
       "233896004        AVNRT  Atrioventricular  Node Reentrant Tachycardia\n",
       "233897008         AVRT        Atrioventricular Reentrant Tachycardia\n",
       "195101003        SAAWR       Sinus Atrium to Atrial Wandering Rhythm\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_labels(data_dir_folder_path, 'ConditionNames_SNOMED-CT.csv', as_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "553038fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 45152\n",
      "    record                                           hea_path  \\\n",
      "0  JS00001  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...   \n",
      "1  JS00002  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...   \n",
      "2  JS00004  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...   \n",
      "3  JS00005  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...   \n",
      "4  JS00006  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...   \n",
      "\n",
      "                                         record_path n_sig     fs  n_samples  \\\n",
      "0  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...    12  500.0     5000.0   \n",
      "1  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...    12  500.0     5000.0   \n",
      "2  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...    12  500.0     5000.0   \n",
      "3  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...    12  500.0     5000.0   \n",
      "4  c:\\Users\\samue\\Desktop\\VS\\Mgr\\mAIN\\Strojove Uc...    12  500.0     5000.0   \n",
      "\n",
      "    age     sex                           dx_codes  \n",
      "0  85.0    Male   [164889003, 59118001, 164934002]  \n",
      "1  59.0  Female             [426177001, 164934002]  \n",
      "2  66.0    Male                        [426177001]  \n",
      "3  73.0  Female  [164890007, 429622005, 428750005]  \n",
      "4  46.0  Female                        [426177001]  \n"
     ]
    }
   ],
   "source": [
    "run_ = True\n",
    "if run_:\n",
    "    rows = []\n",
    "    for hea in iter_header_paths(data_dir_folder_path):\n",
    "        rows.append(parse_header(hea))\n",
    "\n",
    "    meta_df = pd.DataFrame(rows)\n",
    "    print(\"Number of records:\", len(meta_df))\n",
    "    print(meta_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4dc837b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ = True\n",
    "if save_:\n",
    "    meta_df.to_csv('../data/results/complete_metadata_mapping_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3b9f2",
   "metadata": {},
   "source": [
    "common load - ECG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f001b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_paths = list(iter_header_paths(data_dir_folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77eb5adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'record': 'JS00001',\n",
       " 'hea_path': 'c:\\\\Users\\\\samue\\\\Desktop\\\\VS\\\\Mgr\\\\mAIN\\\\Strojove Ucenie\\\\projekt\\\\data\\\\ecg-arrhythmia\\\\WFDBRecords\\\\01\\\\010\\\\JS00001.hea',\n",
       " 'record_path': 'c:\\\\Users\\\\samue\\\\Desktop\\\\VS\\\\Mgr\\\\mAIN\\\\Strojove Ucenie\\\\projekt\\\\data\\\\ecg-arrhythmia\\\\WFDBRecords\\\\01\\\\010\\\\JS00001',\n",
       " 'n_sig': '12',\n",
       " 'fs': 500,\n",
       " 'n_samples': 5000,\n",
       " 'age': 85,\n",
       " 'sex': 'Male',\n",
       " 'dx_codes': [164889003, 59118001, 164934002]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_header(head_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18736c02",
   "metadata": {},
   "source": [
    "### Working with loaded compiled metadata\n",
    "\n",
    "Workflow:\n",
    "1. Build metadata mapping dataset -> each row = 1 patient and their recording\n",
    "2. Map ECG signals to the corresponding -> ECG signal data of the patient (row to signal)\n",
    "3. Utilize streaming -> data on disk has 6gb size\n",
    "\n",
    "4. Multiple modeling pipelines -> model dependent, e.g. we will pass raw ECG to CNN but we need to do some feature extraction first for models such as SVM\n",
    "\n",
    "\n",
    "Resources:\n",
    "- Models:\n",
    "    - scikit-multiflow (incremental learning): https://scikit-multiflow.readthedocs.io/en/stable/index.html\n",
    "    - sklearn streaming: https://scikit-learn.org/stable/computing/scaling_strategies.html\n",
    "\n",
    "- Features:\n",
    "    - ECG data processing tips: https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1649923/full?utm_source=chatgpt.com\n",
    "\n",
    "\n",
    "Approaches:\n",
    "1. ML Pipeline - traditional ML models - e.g. Log regression, SVM, forests, ... - doesnt need streaming we compute features and discard signals\n",
    "2. DL Pipeline - deep learning algos - e.g. CNN, Transformers, ... - we will need to somehow stream rows/batches for fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a496f",
   "metadata": {},
   "source": [
    "#### Research Questions\n",
    "\n",
    "1. Build custom rhytm classification models - evaluate performance and compare to ECG-FM\n",
    "2. Adversarial inputs and explanability - test adversarial inputs and critical intervals (which part of ECG is the most critical for output change), compare to ECG-FM\n",
    "    - the idea here is to find which \"regions\" of the ECG signal is the most critical and also compare with explainability (due dilligence) -> does critical region match param importance?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff63bf1",
   "metadata": {},
   "source": [
    "implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b05d73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ecg_signal(record_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67f684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49ec1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f64b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
